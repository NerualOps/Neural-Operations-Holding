# Minimal production requirements for inference service only
# Â© 2025 Neural Operation's & Holding's LLC. All rights reserved.

# Core web framework
fastapi>=0.100.0
uvicorn>=0.20.0

# Basic utilities
python-dotenv>=1.0.0

# Machine learning / Transformer model (for inference service)
# NOTE: torch is installed separately as CPU-only in build command
numpy>=1.24.0,<2.0.0
tokenizers>=0.13.0
transformers>=4.35.0  # For model loading and quantization support
accelerate>=0.24.0  # For device_map and memory optimization
psutil>=5.9.0  # For checking available RAM
supabase>=2.0.0  # For model bootstrap from Supabase Storage
# Note: bitsandbytes requires CUDA - will gracefully fall back if not available

